{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Installing Dependencies**"
      ],
      "metadata": {
        "id": "tZ8ZvPlDlSn1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "DlJ5GQmLHZPM",
        "outputId": "5c9bab92-e92f-4643-d09d-1c5474c42b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.8-py3-none-any.whl (987 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.6/987.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.19 (from langchain)\n",
            "  Downloading langchain_core-0.2.19-py3-none-any.whl (366 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.5/366.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.86-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.19->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.8 langchain-core-0.2.19 langchain-text-splitters-0.2.2 langsmith-0.1.86 orjson-3.10.6\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl (36 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain_google_genai)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.2.19)\n",
            "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (0.1.86)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.20.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2024.7.4)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
            "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.5.4\n",
            "    Uninstalling google-generativeai-0.5.4:\n",
            "      Successfully uninstalled google-generativeai-0.5.4\n",
            "Successfully installed google-ai-generativelanguage-0.6.6 google-generativeai-0.7.2 langchain_google_genai-1.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "87ff77c8fb2642ee88d2152a4376438d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.2)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.20.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.8)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.19)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting unstructured\n",
            "  Downloading unstructured-0.14.10-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.25.2)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.24.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.7.4)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.27.0 (from unstructured-client->unstructured)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (24.1)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->unstructured-client->unstructured)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.1)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=b9d3412d493d494eba6a71797d805cf72897101adc1c8973c030cce68a3e8146\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, ordered-set, langdetect, jsonpath-python, h11, emoji, backoff, requests-toolbelt, httpcore, deepdiff, httpx, unstructured-client, unstructured\n",
            "Successfully installed backoff-2.2.1 deepdiff-7.0.1 emoji-2.12.1 filetype-1.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpath-python-1.0.6 langdetect-1.0.9 ordered-set-4.1.0 pypdf-4.3.0 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.4 requests-toolbelt-1.0.0 unstructured-0.14.10 unstructured-client-0.24.1\n",
            "Requirement already satisfied: unstructured[pdf] in /usr/local/lib/python3.10/dist-packages (0.14.10)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.12.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.0.9)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.25.2)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.9.4)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.12.2)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.24.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.9.5)\n",
            "Collecting onnx (from unstructured[pdf])\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image (from unstructured[pdf])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Collecting pdfminer.six (from unstructured[pdf])\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pikepdf (from unstructured[pdf])\n",
            "  Downloading pikepdf-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow-heif (from unstructured[pdf])\n",
            "  Downloading pillow_heif-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.3.0)\n",
            "Collecting pytesseract (from unstructured[pdf])\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting google-cloud-vision (from unstructured[pdf])\n",
            "  Downloading google_cloud_vision-3.7.3-py2.py3-none-any.whl (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.4/466.4 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting effdet (from unstructured[pdf])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured-inference==0.7.36 (from unstructured[pdf])\n",
            "  Downloading unstructured_inference-0.7.36-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
            "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
            "Collecting layoutparser (from unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (0.23.4)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (4.8.0.76)\n",
            "Collecting onnxruntime>=1.17.0 (from unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (2.3.0+cu121)\n",
            "Collecting timm (from unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]) (4.41.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (9.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[pdf]) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]) (0.18.0+cu121)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]) (2.0.8)\n",
            "Collecting omegaconf>=2.0 (from effdet->unstructured[pdf])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (2.16.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (42.0.8)\n",
            "Collecting Pillow>=8.0.0 (from unstructured.pytesseract>=0.3.12->unstructured[pdf])\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pikepdf->unstructured[pdf])\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2024.7.4)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (7.0.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (0.27.0)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.16.0)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured[pdf]) (4.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.63.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (0.14.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[pdf])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.13.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]) (3.1.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->unstructured-inference==0.7.36->unstructured[pdf]) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.15.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->unstructured-inference==0.7.36->unstructured[pdf]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.36->unstructured[pdf]) (0.19.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2.0.3)\n",
            "Collecting iopath (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading pdfplumber-0.11.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.2.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unstructured-inference==0.7.36->unstructured[pdf]) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]) (2024.1)\n",
            "Collecting pdfminer.six (from unstructured[pdf])\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[pdf])\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.36->unstructured[pdf]) (1.3.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, iopath\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=303b237fc35b775d5a86ee7e67522b94dd417d3cb6dd5a193a30c89864affc84\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=91d81e2b41cdaadfbcff1b4844e2884d8ec978697eacb1e655c0d582224ae73e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built antlr4-python3-runtime iopath\n",
            "Installing collected packages: antlr4-python3-runtime, python-multipart, pypdfium2, portalocker, Pillow, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, Deprecated, unstructured.pytesseract, pytesseract, pillow-heif, pikepdf, pdf2image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, coloredlogs, pdfminer.six, onnxruntime, nvidia-cusolver-cu12, pdfplumber, layoutparser, google-cloud-vision, timm, unstructured-inference, effdet\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 Pillow-10.4.0 antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 effdet-0.4.1 google-cloud-vision-3.7.3 humanfriendly-10.0 iopath-0.1.10 layoutparser-0.3.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnx-1.16.1 onnxruntime-1.18.1 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.2 pikepdf-9.0.0 pillow-heif-0.17.0 portalocker-2.10.1 pypdfium2-4.30.0 pytesseract-0.3.10 python-multipart-0.0.9 timm-1.0.7 unstructured-inference-0.7.36 unstructured.pytesseract-0.3.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "pydevd_plugins"
                ]
              },
              "id": "99d324afeeb642d694d5de3ed174654b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-ai-generativelanguage in /usr/local/lib/python3.10/dist-packages (0.6.6)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage) (2.16.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.63.2)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-ai-generativelanguage) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage) (2024.7.4)\n",
            "Requirement already satisfied: langchain[docarray] in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "\u001b[33mWARNING: langchain 0.2.8 does not provide the extra 'docarray'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.19 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.2.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (0.1.86)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain[docarray]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain[docarray]) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain[docarray]) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain[docarray]) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain[docarray]) (3.0.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.6 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.7 PyMuPDFb-1.24.6\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.4-py3-none-any.whl (581 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.4/581.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
            "Collecting chroma-hnswlib==0.7.5 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.18.1)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.6)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
            "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=ca401bf43de322f64c31ab912d4f265353a29526898746cb6b590308f9f4ece2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, overrides, opentelemetry-util-http, opentelemetry-proto, importlib-metadata, httptools, dnspython, chroma-hnswlib, bcrypt, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, email_validator, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed asgiref-3.8.1 bcrypt-4.1.3 chroma-hnswlib-0.7.5 chromadb-0.5.4 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 httptools-0.6.1 importlib-metadata-7.1.0 kubernetes-30.1.0 mmh3-4.1.0 monotonic-1.6 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 starlette-0.37.2 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "#installing dependencies, a few here might be redundant. These came up while debugging... So as we say.. don't touch something that's working\n",
        "#this takes about 4-6 mins. and 2 session restarts\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai\n",
        "!pip install google-generativeai\n",
        "!pip install -U langchain-community\n",
        "!pip install unstructured\n",
        "!pip install \"unstructured[pdf]\"\n",
        "!pip install google-ai-generativelanguage\n",
        "!pip install \"langchain[docarray]\"\n",
        "!pip install python-dotenv\n",
        "#!pip install PyPDF2\n",
        "!pip install PyMuPDF\n",
        "# !pip install pdfminer.six\n",
        "!pip install chromadb\n",
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Connecting to Drive In case you have uploaded pdf's to your own drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "E_Y2YNpUH31X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing stuff\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "import fitz\n",
        "import nltk\n",
        "import spacy\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "from google.colab import files\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import urllib\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain.vectorstores import Chroma\n",
        "import re\n",
        "\n",
        "#downloading relavant words for lemmatization and stop words\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "0Li5UOKfHax0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1e3303-4e88-457f-ddf3-184b17bbf827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting up the API Key**\n",
        "Just make a .env file analogous to the .env.example file just insert api key for gemini after the GOOGLE_API_KEY field."
      ],
      "metadata": {
        "id": "EwwMBsLGlsj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the file uploaded here is a .env having the gemini api key formatted as GOOGLE_API_KEY=abcdef123456\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    with open(fn, 'wb') as f:\n",
        "        f.write(uploaded[fn])\n",
        "\n",
        "load_dotenv(fn)\n",
        "api_ke = os.getenv('GOOGLE_API_KEY')\n",
        "\n",
        "#print(api_ke)\n",
        "\n",
        "genai.configure(api_key=api_ke)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "PUofB9dlKO49",
        "outputId": "09050afb-856f-406e-a232-28552bd2233d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95a9b105-d0ed-43bd-956b-c05d0c5b36e0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95a9b105-d0ed-43bd-956b-c05d0c5b36e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving .env to .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initializing The  Gemini Model**"
      ],
      "metadata": {
        "id": "HGuwF6yZmDOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",google_api_key=api_ke,\n",
        "                             temperature=0.2,convert_system_message_to_human=True)"
      ],
      "metadata": {
        "id": "FLjQ6n1_KQrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Processing PDFs**\n",
        "### **Uploading PDFs**\n",
        "Firstly extract and upload the extracted zip folder. Correct the file path as necessary.\n",
        "\n",
        "### **Pre-Processing PDFs**\n",
        "First we download stop words which hold negligible semantic meaning from the library. Then we tokenize using space, furhter we lematize the words while also stripping trailing and leading whitespaces. Finally we convert it into a single string. I had earlier also removed punctuation marks but it was impeding the CG cutoff values.\n",
        "\n",
        "### **Extracting Text From PDFs**\n",
        "We use the PyMuPDF library to extract text from the pdfs. Then we initialize and store  text based on the title of the pdf. So we make a combined list in all_pages and 2 seperate ones for si and placement chronicles"
      ],
      "metadata": {
        "id": "osErC_89mJsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from PyPDF2 import PdfReader\n",
        "pdf_folder_path = \"/content/pdf_files\"\n",
        "\n",
        "pdf_files = [f for f in os.listdir(pdf_folder_path) if f.endswith('.pdf')]\n",
        "\n",
        "all_pages = []\n",
        "pi_pages = []\n",
        "si_pages = []\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # text = re.sub(r'[^\\w\\s+]', '', text)\n",
        "\n",
        "    doc = nlp(text)\n",
        "    # Remove stopwords and lemmatize\n",
        "    processed_words = []\n",
        "    for token in doc:\n",
        "        if token.text.lower() not in stop_words:\n",
        "            processed_words.append(token.lemma_)\n",
        "\n",
        "    processed_text = ' '.join(processed_words).strip()\n",
        "    return processed_text\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    document = fitz.open(pdf_path)\n",
        "    for page_num in range(len(document)):\n",
        "        page = document.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    text = preprocess_text(text)\n",
        "    return text\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    file_name = os.path.splitext(pdf_file)[0]\n",
        "\n",
        "    pdf_path = os.path.join(pdf_folder_path, pdf_file)\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    all_pages.append(text)\n",
        "\n",
        "    if \"placement chronicles\" in file_name.lower():\n",
        "        pi_pages.append(text)\n",
        "    elif \"si chronicles\" in file_name.lower():\n",
        "        si_pages.append(text)\n",
        "\n",
        "#print(all_pages[28].page_content)\n",
        "print(len(all_pages))\n",
        "print(len(si_pages))\n",
        "print(len(pi_pages))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijxyyDoWKcnv",
        "outputId": "cf59ff0b-7703-49e4-bfb1-fd3df233c46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(pi_pages[0])"
      ],
      "metadata": {
        "id": "rbdE-JZ5_ANa",
        "collapsed": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Text Processing**\n",
        "Firstly we combine the pages into a single string removing leading and trailing whitespaces in the process. Then we breaek the text into chunks of desirable size."
      ],
      "metadata": {
        "id": "YE4Q5dxWoRjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=750)\n",
        "\n",
        "context_all = \"\\n\\n\".join(str(p) for p in all_pages)\n",
        "context_pi = \"\\n\\n\".join(str(p) for p in pi_pages)\n",
        "context_si = \"\\n\\n\".join(str(p) for p in si_pages)\n",
        "\n",
        "context_all = context_all.strip()\n",
        "context_pi = context_pi.strip()\n",
        "context_si = context_si.strip()\n",
        "\n",
        "texts = text_splitter.split_text(context_all)\n",
        "pi_texts = text_splitter.split_text(context_pi)\n",
        "si_texts = text_splitter.split_text(context_si)\n",
        "\n",
        "print(len(texts))\n",
        "print(len(pi_texts))\n",
        "print(len(si_texts))\n",
        "\n",
        "# print(\"texts:\", texts)\n",
        "# print(\"pi_texts:\", pi_texts)\n",
        "# print(\"si_texts:\", si_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfnezxXXKeUD",
        "outputId": "18e60922-342f-4832-f3fd-3cd94015e312"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202\n",
            "82\n",
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Making Corresponding Embeddings**\n",
        "Firstly we initialize the embeddings model by gemini. Then we create corresponding embeddings and their retriever using Chromadb."
      ],
      "metadata": {
        "id": "o6uIb6qYolow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=api_ke)\n",
        "\n",
        "vector_index = Chroma.from_texts(texts, embeddings).as_retriever(search_kwargs={\"k\":5})\n",
        "vector_pi = Chroma.from_texts(pi_texts, embeddings).as_retriever(search_kwargs={\"k\":5})\n",
        "vector_si = Chroma.from_texts(si_texts, embeddings).as_retriever(search_kwargs={\"k\":5})"
      ],
      "metadata": {
        "id": "FhSz_DjEODnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Processing Queries**\n",
        "# **Setting a Template**\n",
        "We first give a set of instructions to our  llm model along with each query, which helps it in generating better answers.\n",
        "# **Selecting Appropriate Retriever**\n",
        "We create a function which identifies keywords in the queries given by the user. Then we assign corresponding retriever which has access to the corresponding info. If no keywords are identified we send the combined info of both docs.\n",
        "# **Emphasize Number Function**\n",
        "This function is made to put emphasis on numbers in user queries if any. This is due to the fact it is more likely to get a better result if we can find the exact number in the docs, instead of going the traditional route of semantic seach.\n",
        "# **Building A Q/A Retrieval Chain**\n",
        "In this function we first call the select retriever and the emphasize number function to process the queries first. Then we proceed to build the retrieval Q/A chain with the corresponding model, retriever and template."
      ],
      "metadata": {
        "id": "C4KaPPVtpBKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Use the following context to answer the question at the end.Look into the full context carefully and Don't try to make up answers. Give answers in detail only if asked. You can reference interviewee names and tell their experiences as general answers.Always end your response with \"thanks for asking!\".\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "pi_keywords = [\"placement\", \"placements\"]\n",
        "si_keywords = [\"summer internship\", \"si\", \"summer internships\"]\n",
        "def select_retriever(question):\n",
        "    # if (any(keyword in question.lower() for keyword in pi_keywords) and any(keyword in question.lower() for keyword in si_keywords)):\n",
        "    #     return vector_index\n",
        "    if any(keyword in question.lower() for keyword in pi_keywords):\n",
        "        return vector_pi\n",
        "    elif any(keyword in question.lower() for keyword in si_keywords):\n",
        "        return vector_si\n",
        "    else:\n",
        "        return vector_index\n",
        "def emphasize_numbers(question):\n",
        "    numbers = re.findall(r'\\d+(\\.\\d+)?', question)\n",
        "\n",
        "    emphasized_query = question\n",
        "    for number in numbers:\n",
        "        emphasized_query = emphasized_query.replace(number, f\"{number}^2\")\n",
        "\n",
        "    return emphasized_query\n",
        "\n",
        "\n",
        "def get_qa_chain(question):\n",
        "    emphasized_question = emphasize_numbers(question)\n",
        "    selected_retriever = select_retriever(emphasized_question)\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        model,\n",
        "        retriever=selected_retriever,\n",
        "        return_source_documents=True,\n",
        "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        "    )\n",
        "    return qa_chain"
      ],
      "metadata": {
        "id": "beRLdmmXKi8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def remove_keywords(input_string, keywords):\n",
        "#     # Combine all keywords into a single regex pattern\n",
        "#     pattern = '|'.join(r'\\b{}\\b'.format(re.escape(keyword)) for keyword in keywords)\n",
        "\n",
        "#     # Use re.sub to replace all occurrences with an empty string\n",
        "#     return re.sub(pattern, '', input_string, flags=re.IGNORECASE)\n",
        "\n",
        "# def check_query(question):\n",
        "#     pi_keywords = [\"placement\", \"placements\"]\n",
        "#     si_keywords = [\"summer internship\", \"si\", \"summer internships\"]\n",
        "#     keywords = pi_keywords + si_keywords\n",
        "#     question_lower = question.lower()\n",
        "\n",
        "#     if ((any(word in question_lower for word in pi_keywords) and any(word in question_lower for word in si_keywords))):\n",
        "#         question = remove_keywords(question_lower, keywords)\n",
        "#         print(question)\n",
        "#         result = qa_chain({\"query\": question})\n",
        "#     elif any(word in question_lower for word in pi_keywords):\n",
        "#         question = remove_keywords(question_lower, pi_keywords)\n",
        "#         print(question)\n",
        "#         result = pi_chain({\"query\": question})\n",
        "#     elif any(word in question_lower for word in si_keywords):\n",
        "#         question = remove_keywords(question_lower, si_keywords)\n",
        "#         print(question)\n",
        "#         result = si_chain({\"query\": question})\n",
        "#     else:\n",
        "#         print(question)\n",
        "#         result = qa_chain({\"query\": question})\n",
        "\n",
        "#     return result[\"result\"]"
      ],
      "metadata": {
        "id": "16Q-zOoEKmhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bot Testing**\n",
        "This is just general testing of the bot you can look through this to get an idea of how well the bot works. I have hidden the output for the queries but you can press show hidden output to view the source docs retrieved by the bot."
      ],
      "metadata": {
        "id": "wGNUgLV2ff8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Elaborate on the selection process for Microsoft in summer internship in detail?\"\n",
        "qa_chain = get_qa_chain(question)\n",
        "result = qa_chain({\"query\": question})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIi2iJJbgZui",
        "outputId": "2d0e97af-6a50-489d-f860-9e0e27e2a173",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Elaborate on the selection process for Microsoft in summer internship in detail?',\n",
              " 'result': \"The selection process for Microsoft's summer internship program is quite rigorous and involves multiple rounds. Here's a breakdown based on the information provided:\\n\\n**Eligibility:**\\n\\n* **CG Cutoff:**  The minimum CGPA requirement is 7+ for software engineering internships. For hardware-related roles, the cutoff is 8+.\\n* **Branch:** Open to students from A7, A3, A8, and AA branches (single and dual degree).\\n\\n**Recruitment Process:**\\n\\n**Round 1: Online Assessment (Software Engineering)**\\n\\n* **Duration:** 1.5 hours.\\n* **Content:** Two questions based on basic concepts covered in CS F211 - Data Structures and Algorithms. The difficulty level is rated as easy to medium.\\n* **Key:**  Time management is crucial. Aim to finish as quickly as possible while ensuring accuracy.\\n\\n**Round 2: Technical Interview 1 (Software Engineering)**\\n\\n* **Duration:** Approximately one hour.\\n* **Content:**\\n    * **Introduction:**  Begins with an introduction and discussion about your projects and internship experiences.\\n    * **Technical Depth:**  In-depth questions about the tech stack and concepts used in your projects.\\n    * **Design Patterns:** Basic to moderate questions on design patterns covered in CS F213 - Object-Oriented Programming.\\n    * **Coding:**  A coding question related to concepts covered in CS F211 - Data Structures and Algorithms. You need to pass specific test cases.\\n\\n**Round 3: DSA Interview (Software Engineering)**\\n\\n* **Content:**\\n    * **Project Discussion:**  The interviewer will delve into your resume projects.\\n    * **DSA Segment:**  In-depth discussion on sorting algorithms, likely covering your approach to preparing for DSA interviews using LeetCode and the CS F211 course content.  Expect detailed discussions on quick sort and merge sort.\\n\\n**Round 4: CS Fundamentals Interview (Software Engineering)**\\n\\n* **Content:**  This round focuses on your understanding of fundamental computer science concepts.\\n\\n**Round 1: Online Assessment (Hardware Engineering)**\\n\\n* **Duration:**  Not specified.\\n* **Content:**  Three challenging coding questions. Examples include:\\n    * Implementing a spiral output given a starting corner.\\n    * A question based on graphs, described as particularly tricky.\\n    * A problem involving dynamic programming, binary search, and bitmasking.\\n\\n**Round 2: Online Assessment 2 (Hardware Engineering)**\\n\\n* **Content:**  Shortlisting round, likely based on the previous round and your resume.  The questions are relatively easy and short in duration.  They focus on implementation-based problems, comparable to medium-level LeetCode questions.  The questions are more design-based than purely algorithmic.\\n\\n**Round 2: Technical Interview (Hardware Engineering)**\\n\\n* **Content:**  The round mainly covers questions based on ECE/EEE/INSTR F215 - Digital Design. It also includes basic questions related to the third-year course CDC - EEE/INSTR F313 - Analog Digital VLSI Design.  While not a specific course requirement, it's helpful to understand basic concepts like Static Time Analysis.  The interview will focus on topics covered in the courses.\\n\\n**Round 3: Personal Interview (Hardware Engineering)**\\n\\n* **Duration:**  Approximately 40 minutes.\\n* **Content:**  This round is like a personality test.  You'll be presented with situations and asked questions to gauge your professional ethics and how you would respond to different situations.  The interview also assesses your ability to handle challenging situations.\\n\\n**General Advice:**\\n\\n* **Confidence:**  Be confident in your answers, even if you get stuck.\\n* **Communication:**  Keep interacting with the interviewer and share your thought process.\\n* **Preparation:**  Thoroughly prepare for OOP concepts, especially for software engineering roles.\\n* **Fundamentals:**  Ensure you have a strong understanding of fundamental concepts, especially for hardware engineering roles.\\n* **Resources:**  Use online resources like GeeksforGeeks for general preparation and hdlbits to get comfortable with Verilog for hardware engineering.\\n\\nThanks for asking! \\n\",\n",
              " 'source_documents': [Document(page_content='CG Cutoff - 8 + \\n recruitment process - \\u2028\\n Round 1 - Resume Shortlisting \\n\\n Round 2 - Technical Interview \\n\\n round mainly cover question base ECE / EEE / INSTR F215 - \\n Digital Design . also basic question pertain third- \\n year CDC - EEE / INSTR F313 - Analog Digital VLSI Design . though \\n not course would take time interview , sure \\n learn basic concept like Static Time Analysis . specifically ask \\n question pertain topic interview . \\n\\n also ask question base fundamental \\n programming like Fibonacci series , well Computer \\n Architecture . first ask basic part computer \\n memory organize . also ask question base \\n pipeline , delay occur hazard .  \\n Microsoft Corporation \\n 37 \\n Round 3 - Personal Interview \\n\\n almost like 40 minute - long personality test . give \\n situation ask different question gauge professional \\n ethic , well would respond react different situation . \\n\\n also try test situation - handle ability round \\n Personal Experiences \\n source preparation - \\n\\n well verse dd also find online resource \\n make familiar ADVD , would do . \\n use hdlbits get comfortable Verilog . basic programming \\n concept , could use general source preparation \\n geeksforgeek . \\n\\n word Advice -'),\n",
              "  Document(page_content='CG Cutoff - 8 + \\n recruitment process - \\u2028\\n Round 1 - Resume Shortlisting \\n\\n Round 2 - Technical Interview \\n\\n round mainly cover question base ECE / EEE / INSTR F215 - \\n Digital Design . also basic question pertain third- \\n year CDC - EEE / INSTR F313 - Analog Digital VLSI Design . though \\n not course would take time interview , sure \\n learn basic concept like Static Time Analysis . specifically ask \\n question pertain topic interview . \\n\\n also ask question base fundamental \\n programming like Fibonacci series , well Computer \\n Architecture . first ask basic part computer \\n memory organize . also ask question base \\n pipeline , delay occur hazard .  \\n Microsoft Corporation \\n 37 \\n Round 3 - Personal Interview \\n\\n almost like 40 minute - long personality test . give \\n situation ask different question gauge professional \\n ethic , well would respond react different situation . \\n\\n also try test situation - handle ability round \\n Personal Experiences \\n source preparation - \\n\\n well verse dd also find online resource \\n make familiar ADVD , would do . \\n use hdlbits get comfortable Verilog . basic programming \\n concept , could use general source preparation \\n geeksforgeek . \\n\\n word Advice -'),\n",
              "  Document(page_content='word Advice - \\n\\n not mention skill / project resume \\n confident answer . make sure prepare OOP thoroughly . even \\n get stick somewhere interview , keep interact \\n interviewer tell every thought come mind . \\n interviewer help often will tell be go \\n right direction . thought process matter know actual \\n concept . \\n Round 2 - Technical Interview \\n\\n round last around hour . begin introduction , \\n follow - depth discussion around project prior internship \\n experience . first , ask basic question around tech stack \\n concept use project . proceed ask - depth \\n question around stack concept . \\n follow , ask basic moderate question around design \\n pattern basic concept cover CS F213 - object - orient \\n Programming . conclude , ask code question pertain \\n concept cover CS F211 - Data Structures Algorithms \\n pass certain test case . \\n Microsoft Corporation \\n 80 \\n introduction \\n Interviewee - Vaibhav Singla ( 2021a7ps2227p ) \\n Job Role - Software Engineer Intern \\n Number offer make - 4 \\n Selection Process \\n branch open - A7 , A3 , A8 , AA - single dual degree \\n student eligible appear process \\n\\n CG Cutoff - 7 + \\n Recruitment process - \\u2028\\n Round 1 - Online Assessment \\n\\n last 1.5 hour . two question base basic \\n concept cover CS F211 - Data Structures Algorithms would \\n rate easy medium . time give ample key finish \\n fast possible submission time good . \\r\\n\\n Round 2 - technical Interview 1'),\n",
              "  Document(page_content='word Advice - \\n\\n not mention skill / project resume \\n confident answer . make sure prepare OOP thoroughly . even \\n get stick somewhere interview , keep interact \\n interviewer tell every thought come mind . \\n interviewer help often will tell be go \\n right direction . thought process matter know actual \\n concept . \\n Round 2 - Technical Interview \\n\\n round last around hour . begin introduction , \\n follow - depth discussion around project prior internship \\n experience . first , ask basic question around tech stack \\n concept use project . proceed ask - depth \\n question around stack concept . \\n follow , ask basic moderate question around design \\n pattern basic concept cover CS F213 - object - orient \\n Programming . conclude , ask code question pertain \\n concept cover CS F211 - Data Structures Algorithms \\n pass certain test case . \\n Microsoft Corporation \\n 80 \\n introduction \\n Interviewee - Vaibhav Singla ( 2021a7ps2227p ) \\n Job Role - Software Engineer Intern \\n Number offer make - 4 \\n Selection Process \\n branch open - A7 , A3 , A8 , AA - single dual degree \\n student eligible appear process \\n\\n CG Cutoff - 7 + \\n Recruitment process - \\u2028\\n Round 1 - Online Assessment \\n\\n last 1.5 hour . two question base basic \\n concept cover CS F211 - Data Structures Algorithms would \\n rate easy medium . time give ample key finish \\n fast possible submission time good . \\r\\n\\n Round 2 - technical Interview 1'),\n",
              "  Document(page_content='CG Cutoff - 7 + \\n Recruitment process - \\u2028\\n Round 1 - Online Assessment 1 \\n\\n test purely code - base . three question quite difficult . \\n were:\\x91 \\n \\x8b » implementation spiral output give start corne\\x98 \\n\\x85 » one base graph - particularly trick\\x95 \\n ¨ » Dynamic Programming , binary search bitmaske \\n\\n Round 2 - Online Assessment 2 \\n\\n shortlisting round likely base previous \\n round also basis resume . round relatively easy \\n short duration . question ask implementation- \\n base would likely correspond medium level Leetcode . \\n question exactly algorithmic , almost design- \\n base . \\n devrev \\n 67 \\n Personal Experiences \\n source preparation - \\n\\n primarily revise course material Codeforces \\n Leetcode problem - solve \\n\\n word Advice - \\n\\n sure thorough fundamental appear \\n process especially . \\n Relevant Courses Certification \\n |s CS F211 - Data Structures Algorithmd \\n _ CS F213 - Object - Oriented Programminz \\n \\\\ CS F222 - Discrete Structures Computer Science \\n Round 3 - DSA Interview \\n\\n interviewer knowledgeable question ask \\n - depth . start ask resume project . follow \\n , get DSA segment . start discussion sort \\n algorithm , great detail . likely cover student \\n approach SI preparation Leetcode , cover CS F211 \\n - Data Structures Algorithms course . even , in- \\n depth discussion quick sort merge sort . \\n\\n round 4 - CS Fundamental Interviews')]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gb-hGzDbgi-v",
        "outputId": "a1754d5e-5f93-4f1f-84e6-77f64acab853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The selection process for Microsoft's summer internship program is quite rigorous and involves multiple rounds. Here's a breakdown based on the information provided:\n\n**Eligibility:**\n\n* **CG Cutoff:**  The minimum CGPA requirement is 7+ for software engineering internships. For hardware-related roles, the cutoff is 8+.\n* **Branch:** Open to students from A7, A3, A8, and AA branches (single and dual degree).\n\n**Recruitment Process:**\n\n**Round 1: Online Assessment (Software Engineering)**\n\n* **Duration:** 1.5 hours.\n* **Content:** Two questions based on basic concepts covered in CS F211 - Data Structures and Algorithms. The difficulty level is rated as easy to medium.\n* **Key:**  Time management is crucial. Aim to finish as quickly as possible while ensuring accuracy.\n\n**Round 2: Technical Interview 1 (Software Engineering)**\n\n* **Duration:** Approximately one hour.\n* **Content:**\n    * **Introduction:**  Begins with an introduction and discussion about your projects and internship experiences.\n    * **Technical Depth:**  In-depth questions about the tech stack and concepts used in your projects.\n    * **Design Patterns:** Basic to moderate questions on design patterns covered in CS F213 - Object-Oriented Programming.\n    * **Coding:**  A coding question related to concepts covered in CS F211 - Data Structures and Algorithms. You need to pass specific test cases.\n\n**Round 3: DSA Interview (Software Engineering)**\n\n* **Content:**\n    * **Project Discussion:**  The interviewer will delve into your resume projects.\n    * **DSA Segment:**  In-depth discussion on sorting algorithms, likely covering your approach to preparing for DSA interviews using LeetCode and the CS F211 course content.  Expect detailed discussions on quick sort and merge sort.\n\n**Round 4: CS Fundamentals Interview (Software Engineering)**\n\n* **Content:**  This round focuses on your understanding of fundamental computer science concepts.\n\n**Round 1: Online Assessment (Hardware Engineering)**\n\n* **Duration:**  Not specified.\n* **Content:**  Three challenging coding questions. Examples include:\n    * Implementing a spiral output given a starting corner.\n    * A question based on graphs, described as particularly tricky.\n    * A problem involving dynamic programming, binary search, and bitmasking.\n\n**Round 2: Online Assessment 2 (Hardware Engineering)**\n\n* **Content:**  Shortlisting round, likely based on the previous round and your resume.  The questions are relatively easy and short in duration.  They focus on implementation-based problems, comparable to medium-level LeetCode questions.  The questions are more design-based than purely algorithmic.\n\n**Round 2: Technical Interview (Hardware Engineering)**\n\n* **Content:**  The round mainly covers questions based on ECE/EEE/INSTR F215 - Digital Design. It also includes basic questions related to the third-year course CDC - EEE/INSTR F313 - Analog Digital VLSI Design.  While not a specific course requirement, it's helpful to understand basic concepts like Static Time Analysis.  The interview will focus on topics covered in the courses.\n\n**Round 3: Personal Interview (Hardware Engineering)**\n\n* **Duration:**  Approximately 40 minutes.\n* **Content:**  This round is like a personality test.  You'll be presented with situations and asked questions to gauge your professional ethics and how you would respond to different situations.  The interview also assesses your ability to handle challenging situations.\n\n**General Advice:**\n\n* **Confidence:**  Be confident in your answers, even if you get stuck.\n* **Communication:**  Keep interacting with the interviewer and share your thought process.\n* **Preparation:**  Thoroughly prepare for OOP concepts, especially for software engineering roles.\n* **Fundamentals:**  Ensure you have a strong understanding of fundamental concepts, especially for hardware engineering roles.\n* **Resources:**  Use online resources like GeeksforGeeks for general preparation and hdlbits to get comfortable with Verilog for hardware engineering.\n\nThanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How can I prepare for personality interview in Nvidia?\"\n",
        "qa_chain = get_qa_chain(question)\n",
        "result = qa_chain({\"query\": question})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6eJixI-Ni8HQ",
        "outputId": "b98786cf-0ed8-44c0-9986-d8a20e6876ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How can I prepare for personality interview in Nvidia?',\n",
              " 'result': \"Based on the provided information, the personality interview at Nvidia focuses on assessing your communication skills, problem-solving abilities, and cultural fit. Here's how you can prepare:\\n\\n* **Practice answering common HR questions:**  The interviewee, Satvik Jain, suggests practicing answers to HR questions in advance. This includes questions about your interest in the company, your career goals, and your strengths and weaknesses.\\n* **Highlight your relevant skills:**  Nvidia's technical interview focuses on your understanding of computer architecture, digital design, and microprocessors. Be prepared to discuss your experience with these concepts and how they relate to the role you're applying for.\\n* **Demonstrate your problem-solving skills:**  The technical interview may involve coding challenges or questions that require you to think critically and apply your knowledge. Practice solving problems using different approaches and be prepared to explain your thought process.\\n* **Show your enthusiasm and passion:**  Nvidia values candidates who are passionate about technology and eager to learn. Express your interest in the company and the specific role you're applying for.\\n* **Research the company and the role:**  Before the interview, take the time to learn about Nvidia's culture, values, and current projects. This will help you tailor your responses and demonstrate your genuine interest.\\n\\nRemember, the personality interview is an opportunity to showcase your personality and connect with the interviewer on a personal level. Be confident, enthusiastic, and authentic.\\n\\nThanks for asking! \\n\",\n",
              " 'source_documents': [Document(page_content='CG Cutoff - 8 + \\n recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round highly competitive , question pertain \\n second - year electrical cdc . make round particularly hard . \\n big reason say competitive , however , 4 \\n people shortlist interview round . \\n\\n Round 2 - Technical Interview \\n\\n primarily ask conceptual question course like ECE / EEE/ \\n INSTR F212 - Digital Design , well ECE / EEE / instr F241 - \\n Microprocessors Interfacing . \\n\\n also ask basic question Computer Architecture . \\n third year CDC CS student ( CS F342 ) DEl electrical \\n student , brush basic concept cover course would \\n useful . \\n Nvidia \\n 39 \\n Personal Experiences \\n source preparation - \\n\\n revise note second year . sufficient , \\n especially skim quickly revise important concept . \\n\\n word Advice - \\n\\n stay calm confident especially technical test , fair \\n question slightly tricky . sure prepare thoroughly round , \\n lot candidate primary mean filtration .'),\n",
              "  Document(page_content='CG Cutoff - 8 + \\n recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round highly competitive , question pertain \\n second - year electrical cdc . make round particularly hard . \\n big reason say competitive , however , 4 \\n people shortlist interview round . \\n\\n Round 2 - Technical Interview \\n\\n primarily ask conceptual question course like ECE / EEE/ \\n INSTR F212 - Digital Design , well ECE / EEE / instr F241 - \\n Microprocessors Interfacing . \\n\\n also ask basic question Computer Architecture . \\n third year CDC CS student ( CS F342 ) DEl electrical \\n student , brush basic concept cover course would \\n useful . \\n Nvidia \\n 39 \\n Personal Experiences \\n source preparation - \\n\\n revise note second year . sufficient , \\n especially skim quickly revise important concept . \\n\\n word Advice - \\n\\n stay calm confident especially technical test , fair \\n question slightly tricky . sure prepare thoroughly round , \\n lot candidate primary mean filtration .'),\n",
              "  Document(page_content='use GeeksforGeeks revise C++ Leetcode problem - solve \\n DSA . \\n\\n word Advice - \\n\\n Practice answer hr question advance , interview \\n 15 - 20 min , not efficient technical segment take \\n much time hr segment . \\n additionally , start competitive code least 2 - 2 early , \\n need time able land dream si offer . \\n moreover , also correlate concept teach \\n course , convenient . \\n Round 2 - technical HR Interview \\n\\n round start introduction basic hr question around \\n company interest . begin technical segment , \\n start ask least 2 programming language \\n comfortable . state comfort C++ Python , \\n start ask basic question around . , ask \\n mysql question , like , give complicated query ask \\n compiler would compile first . \\n question ask quite conceptual nature . \\n Nvidia \\n 84 \\n introduction \\n Interviewee - Satvik Jain ( 2020B3A70791P ) \\n Job Role - System Software Intern \\n Number offer make - 3 \\n Selection Process \\n branch open - A7 , A3 , A8 , AA - single dual degree student \\n eligible role \\n\\n CG Cutoff - None \\n Recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round two segmentsµ \\n äÉ Logical Reasonin » \\n ³É Coding - round two question , would likely fall \\n medium category Leetcode . tell we prior start \\n round c would allow round assessment . \\n one question debug give piece code \\n\\n Round 2 - technical interview'),\n",
              "  Document(page_content='use GeeksforGeeks revise C++ Leetcode problem - solve \\n DSA . \\n\\n word Advice - \\n\\n Practice answer hr question advance , interview \\n 15 - 20 min , not efficient technical segment take \\n much time hr segment . \\n additionally , start competitive code least 2 - 2 early , \\n need time able land dream si offer . \\n moreover , also correlate concept teach \\n course , convenient . \\n Round 2 - technical HR Interview \\n\\n round start introduction basic hr question around \\n company interest . begin technical segment , \\n start ask least 2 programming language \\n comfortable . state comfort C++ Python , \\n start ask basic question around . , ask \\n mysql question , like , give complicated query ask \\n compiler would compile first . \\n question ask quite conceptual nature . \\n Nvidia \\n 84 \\n introduction \\n Interviewee - Satvik Jain ( 2020B3A70791P ) \\n Job Role - System Software Intern \\n Number offer make - 3 \\n Selection Process \\n branch open - A7 , A3 , A8 , AA - single dual degree student \\n eligible role \\n\\n CG Cutoff - None \\n Recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round two segmentsµ \\n äÉ Logical Reasonin » \\n ³É Coding - round two question , would likely fall \\n medium category Leetcode . tell we prior start \\n round c would allow round assessment . \\n one question debug give piece code \\n\\n Round 2 - technical interview'),\n",
              "  Document(page_content='CG Cutoff - None \\n Recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round two segmentsµ \\n äÉ Logical Reasonin » \\n ³É Coding - round two question , would likely fall \\n medium category Leetcode . tell we prior start \\n round c would allow round assessment . \\n one question debug give piece code \\n\\n Round 2 - technical interview \\n\\n round last around 50 min . particular language mention \\n language allow use . start ask \\n basic DSA question . included:-\\x8c \\n äÉ would remove repeat element string¶ \\n ³É give array integer , find maximum sum pair number \\n array . \\n conclude ask basic question CS F215 - \\n Digital Design CS F241 - Microprocessors Interfacing . \\n Nvidia \\n 85 \\n Relevant Courses Certification \\n G > CS F211 - Data Structures Algorithm/ \\n \\' > CS F213 - Object - orient programminc \\n\\x1c > CS / ECE / EEE / INSTR F215 - Digital Desig , \\n F > CS / ECE / EEE / instr F241 - Microprocessors Interfacing \\n Personal Experiences \\n source preparation -\\x91 \\n k DSA Revision - Striver ’s SDE Sheev \\n k DSA Problem - solving - Leetcode , InterviewBiv \\n k Interview preparation - GeeksforGeeks \\n\\n word Advice - \\n\\n lot company might either give direction around \\n expect and/or prepare interview , give direction , \\n process might reflect . similar experience \\n SI hiring process . \\n\\n thus , could stress importance retain strong \\n foundation basic , catch tricky spot \\n event question slightly \" average interview framework \" \\n ask . \\n Round 3 - hr Interview')]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "FWvBDLA5jZwR",
        "outputId": "be5e07ab-3f6c-43a8-de5a-1f54592e8f47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the provided information, the personality interview at Nvidia focuses on assessing your communication skills, problem-solving abilities, and cultural fit. Here's how you can prepare:\n\n* **Practice answering common HR questions:**  The interviewee, Satvik Jain, suggests practicing answers to HR questions in advance. This includes questions about your interest in the company, your career goals, and your strengths and weaknesses.\n* **Highlight your relevant skills:**  Nvidia's technical interview focuses on your understanding of computer architecture, digital design, and microprocessors. Be prepared to discuss your experience with these concepts and how they relate to the role you're applying for.\n* **Demonstrate your problem-solving skills:**  The technical interview may involve coding challenges or questions that require you to think critically and apply your knowledge. Practice solving problems using different approaches and be prepared to explain your thought process.\n* **Show your enthusiasm and passion:**  Nvidia values candidates who are passionate about technology and eager to learn. Express your interest in the company and the specific role you're applying for.\n* **Research the company and the role:**  Before the interview, take the time to learn about Nvidia's culture, values, and current projects. This will help you tailor your responses and demonstrate your genuine interest.\n\nRemember, the personality interview is an opportunity to showcase your personality and connect with the interviewer on a personal level. Be confident, enthusiastic, and authentic.\n\nThanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"which company had CG cutoff as more than 8 in placements\"\n",
        "qa_chain = get_qa_chain(question)\n",
        "result = qa_chain({\"query\": question})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX7raiWDKoHg",
        "outputId": "02e1b74c-80af-4ed7-ee93-49ea765a1c65",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'which company had CG cutoff as more than 8 in placements',\n",
              " 'result': 'The company with a CG cutoff of more than 8 in placements is **Millennium Management**. \\n\\nthanks for asking! \\n',\n",
              " 'source_documents': [Document(page_content='CG Cutoff - 8 + \\n recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round mcq base Math Probability . besides , \\n code question . \\n\\n Round 2 - Puzzle - Based Interview \\n\\n ask various mathematical puzzle brain teaser 25 minute . \\n find even practice book video \\n mention next page . \\n\\n Round 3 - Technical interview \\n\\n round start fairly easy puzzle . however , move \\n technical segment fairly quickly , puzzle standard . \\n part , ask code run three question . likely \\n correspond medium hard difficulty level Leetcode . \\n Millennium Management \\n 117 \\n Round 4 - hr Interview \\n\\n round call hr round , start \\n moderately hard mathematical puzzle . solve , proceed \\n hr segment . , ask general question around resume , \\n well competitive code background . besides , ask \\n hobby long - term plan , well expectation \\n role intent behind join . \\n Personal Experiences \\n Project Internship experience - « \\n \\x8a\\x9c Projects - three project CS itsel\\x7f \\n l\\x9c internship - PS - Amazon , Machine Learning team , \\n prove good learning experience also good \\n talk poino \\n \\x8f\\x9c Academics - CGPA 10/10 , make Institute Rank 1 . \\n\\n source preparation - \\n\\n pursue competitive coding two year \\n participate contest Leetcode , Codeforces , CodeChef . \\n quant puzzle , stick Brainstellar . \\n\\n word Advice -'),\n",
              "  Document(page_content='CG Cutoff - 8 + \\n recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round mcq base Math Probability . besides , \\n code question . \\n\\n Round 2 - Puzzle - Based Interview \\n\\n ask various mathematical puzzle brain teaser 25 minute . \\n find even practice book video \\n mention next page . \\n\\n Round 3 - Technical interview \\n\\n round start fairly easy puzzle . however , move \\n technical segment fairly quickly , puzzle standard . \\n part , ask code run three question . likely \\n correspond medium hard difficulty level Leetcode . \\n Millennium Management \\n 117 \\n Round 4 - hr Interview \\n\\n round call hr round , start \\n moderately hard mathematical puzzle . solve , proceed \\n hr segment . , ask general question around resume , \\n well competitive code background . besides , ask \\n hobby long - term plan , well expectation \\n role intent behind join . \\n Personal Experiences \\n Project Internship experience - « \\n \\x8a\\x9c Projects - three project CS itsel\\x7f \\n l\\x9c internship - PS - Amazon , Machine Learning team , \\n prove good learning experience also good \\n talk poino \\n \\x8f\\x9c Academics - CGPA 10/10 , make Institute Rank 1 . \\n\\n source preparation - \\n\\n pursue competitive coding two year \\n participate contest Leetcode , Codeforces , CodeChef . \\n quant puzzle , stick Brainstellar . \\n\\n word Advice -'),\n",
              "  Document(page_content='CG Cutoff - 7.5 + \\n Recruitment process - \\u2028\\n Round 1 - Online Assessment \\n\\n test ~15 question . question primarily base logic , \\n probability , statistic , SQL . question could solve \\n decent knowledge MATH F112 : Probability Statistics , 1 \\n high - weightage SQL - base question ask . \\n\\n Round 2 - Technical Interview \\n\\n round mainly focus SQL . three parts:~ \\n Ã · previous work / project ’ discussion - round , ask detail \\n question base CS F212 - Database Systems projec¢ \\n \\x82 · business case study - ask solve case study use data- \\n drive approach . concept teach ECON F241 - Econometric \\n Methods come handy · \\n § · code round - round , question datum give ask . \\n code use SQL HackerRank , could not run code . \\n Atlassian \\n 28 \\n Round 3 - Behavioural Interview'),\n",
              "  Document(page_content='CG Cutoff - 7.5 + \\n Recruitment process - \\u2028\\n Round 1 - Online Assessment \\n\\n test ~15 question . question primarily base logic , \\n probability , statistic , SQL . question could solve \\n decent knowledge MATH F112 : Probability Statistics , 1 \\n high - weightage SQL - base question ask . \\n\\n Round 2 - Technical Interview \\n\\n round mainly focus SQL . three parts:~ \\n Ã · previous work / project ’ discussion - round , ask detail \\n question base CS F212 - Database Systems projec¢ \\n \\x82 · business case study - ask solve case study use data- \\n drive approach . concept teach ECON F241 - Econometric \\n Methods come handy · \\n § · code round - round , question datum give ask . \\n code use SQL HackerRank , could not run code . \\n Atlassian \\n 28 \\n Round 3 - Behavioural Interview'),\n",
              "  Document(page_content='CG Cutoff - 7.5 + \\n Recruitment process - \\u2028\\n Round 1 - Online assessment \\n\\n round purely code round four question . \\n question could solve thorough understanding concept teach \\n CS F211 - Data Structures Algorithms . question rely \\n Dynamic Programming and/or Graphs , standard oas . \\n\\n Round 2 - technical Interview 1 \\n\\n round singularly base CS F211 - Data Structures \\n Algorithms , ask lot - depth question Graphs . \\n question definitely require strong background DSA \\n competitive coding . nearly every question ask , interestingly , \\n graph - base . \\n\\n Round 3 - Technical Interview 2 \\n\\n round singularly base CS F212 - Database Systems . \\n question ask quite conceptual could easily \\n solve follow thorough revision course material . \\n Rubrik \\n 89 \\n Relevant Courses Certification \\n 6 . CS F211 - Data Structures Algorithm ! \\n\\x1c . CS F212 - Database Systems \\n Personal Experiences \\n source preparation -\\x80 \\n g DSA - Leetcodi \\n g DBS - course sufficienm \\n g Problem - solving - Codeforce ! \\n g Interview Preparation - InterviewBit , GeeksforGeeks \\n\\n word Advice -')]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "I79jsSn4hJas",
        "outputId": "268a0b3a-4d6f-46cd-833f-5b768cbda1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The company with a CG cutoff of more than 8 in placements is **Millennium Management**. \n\nthanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the relevant courses for cohesity ?\"\n",
        "qa_chain = get_qa_chain(question)\n",
        "result = qa_chain({\"query\": question})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbK6fNPDKrVI",
        "outputId": "9627d022-c05b-4d16-8d56-557f2dca7d56",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What are the relevant courses for cohesity ?',\n",
              " 'result': \"The provided text doesn't contain information about relevant courses for Cohesity. It only mentions the relevant courses for the interviewee Hemant Seshadri Nemani and Sukriti Phogat. \\n\\nThanks for asking! \\n\",\n",
              " 'source_documents': [Document(page_content='word Advice - \\n\\n please skip class . tedious may , ensure \\n fundamental remain strong throughout . \\n Relevant Courses Certification \\n QH EEE f111 - electrical scienc= \\n # h ECE / EEE / instr F241 - Microprocessors Interfacin~ \\n _ H ECE / EEE / INSTR F242 - Control SystemA \\n\\xa0 H ECE / EEE / INSTR F243 - Signals SystemA \\n \\x9dH ECE / EEE / INSTR F244 - Microelectronic Circuits \\n Information Technology \\n 50 \\n Accenture \\n 52 \\n arcesium \\n 56 \\n Capital one \\n DE Shaw \\n DevRev \\n eightfold.ai \\n 68 \\n Flipkart \\n 70 \\n Goldman Sachs \\n 72 \\n IMC Trading \\n Google \\n 74 \\n Jaguar Land Rover \\n Cohesity \\n 62 \\n Amazon \\n 54 \\n Information Technology \\n 50 \\n Accenture \\n Arcesium \\n Capital One \\n Axis Bank \\n 58 \\n DE Shaw \\n 66 \\n eightfold.ai \\n Flipkart \\n Goldman Sachs \\n Google \\n 78 \\n Cohesity \\n 60 \\n Amazon \\n 76 \\n 64 \\n Information Technology \\n 50 \\n Société Générale \\n Tata Steel \\n Uber \\n Wells Fargo \\n 104 \\n Sprinklr \\n 98 \\n 86 \\n Nvidia \\n 84 \\n Information Technology \\n 51 \\n Rubrik \\n Samsung \\n NPCI \\n Microsoft \\n P&G \\n 80 \\n 82 \\n 90 \\n 88 \\n Present Previous recruiter \\n 102 \\n 100 \\n 96 \\n Accenture \\n 52 \\n introduction \\n Interviewee - Hemant Seshadri Nemani ( 2021AAPS2170P ) \\n Job Role - Advance Application Engineering Intern \\n Number offer make - 3 \\n Selection Process \\n branch open - except A7 - single dual degree student \\n eligible \\n\\n CG Cutoff - 7 + \\n Recruitment process - \\u2028\\n Round 1 - Resume Shortlisting \\n\\n Round 2 - Online assessment'),\n",
              "  Document(page_content='word Advice - \\n\\n please skip class . tedious may , ensure \\n fundamental remain strong throughout . \\n Relevant Courses Certification \\n QH EEE f111 - electrical scienc= \\n # h ECE / EEE / instr F241 - Microprocessors Interfacin~ \\n _ H ECE / EEE / INSTR F242 - Control SystemA \\n\\xa0 H ECE / EEE / INSTR F243 - Signals SystemA \\n \\x9dH ECE / EEE / INSTR F244 - Microelectronic Circuits \\n Information Technology \\n 50 \\n Accenture \\n 52 \\n arcesium \\n 56 \\n Capital one \\n DE Shaw \\n DevRev \\n eightfold.ai \\n 68 \\n Flipkart \\n 70 \\n Goldman Sachs \\n 72 \\n IMC Trading \\n Google \\n 74 \\n Jaguar Land Rover \\n Cohesity \\n 62 \\n Amazon \\n 54 \\n Information Technology \\n 50 \\n Accenture \\n Arcesium \\n Capital One \\n Axis Bank \\n 58 \\n DE Shaw \\n 66 \\n eightfold.ai \\n Flipkart \\n Goldman Sachs \\n Google \\n 78 \\n Cohesity \\n 60 \\n Amazon \\n 76 \\n 64 \\n Information Technology \\n 50 \\n Société Générale \\n Tata Steel \\n Uber \\n Wells Fargo \\n 104 \\n Sprinklr \\n 98 \\n 86 \\n Nvidia \\n 84 \\n Information Technology \\n 51 \\n Rubrik \\n Samsung \\n NPCI \\n Microsoft \\n P&G \\n 80 \\n 82 \\n 90 \\n 88 \\n Present Previous recruiter \\n 102 \\n 100 \\n 96 \\n Accenture \\n 52 \\n introduction \\n Interviewee - Hemant Seshadri Nemani ( 2021AAPS2170P ) \\n Job Role - Advance Application Engineering Intern \\n Number offer make - 3 \\n Selection Process \\n branch open - except A7 - single dual degree student \\n eligible \\n\\n CG Cutoff - 7 + \\n Recruitment process - \\u2028\\n Round 1 - Resume Shortlisting \\n\\n Round 2 - Online assessment'),\n",
              "  Document(page_content='lecture aforementioned course truly beneficial \\n valuable . provide insightful knowledge clarity subject \\n matter . course enhance understanding . \\n word advice - \\n\\n instead skim everything , focus master basic \\n important topic . be like build strong foundation house ; \\n , tackle anything confidence understanding . \\n \\x95v EEE F111 - electrical Sciences\\x8e \\n \\x81v EEE / instr F244 - Microelectronic Circuits\\x8e \\n ov EEE F313 - Analog Digital VLSI Design\\x8e \\n sv CS F111 - Computer Programmin~ \\n gv Math course - MATH F111 ( Mathematics ) , MATH F112 ( Mathematics II ) , \\n MATH F211 ( Mathematics III ) \\n Relevant Courses Certifications \\n Round 5 - hr Interview \\n\\n Basic HR Questions ask , like skill , good fit \\n job , willing relocate , etc . \\n SEDEMAC Mechatronics Pvt Ltd \\n 34 \\n introduction \\n Interviewee - Sukriti Phogat ( 2020a7ps0071p ) \\n Job Role - Engineer , Embedded Software \\n Number offer make - 1 \\n Selection Process \\n branch open - CS , EEE , ENI \\n CG Cutoff - 6 + \\n recruitment process - \\n Round 1 - Online Assessment \\n\\n round consist 5 question base Data Structures \\n Algorithms . easy . \\n Round 2 - technical interview \\n\\n round aim test fundamental Data Structures \\n Algorithms . \\n Round 3 - Technical Interview II'),\n",
              "  Document(page_content='lecture aforementioned course truly beneficial \\n valuable . provide insightful knowledge clarity subject \\n matter . course enhance understanding . \\n word advice - \\n\\n instead skim everything , focus master basic \\n important topic . be like build strong foundation house ; \\n , tackle anything confidence understanding . \\n \\x95v EEE F111 - electrical Sciences\\x8e \\n \\x81v EEE / instr F244 - Microelectronic Circuits\\x8e \\n ov EEE F313 - Analog Digital VLSI Design\\x8e \\n sv CS F111 - Computer Programmin~ \\n gv Math course - MATH F111 ( Mathematics ) , MATH F112 ( Mathematics II ) , \\n MATH F211 ( Mathematics III ) \\n Relevant Courses Certifications \\n Round 5 - hr Interview \\n\\n Basic HR Questions ask , like skill , good fit \\n job , willing relocate , etc . \\n SEDEMAC Mechatronics Pvt Ltd \\n 34 \\n introduction \\n Interviewee - Sukriti Phogat ( 2020a7ps0071p ) \\n Job Role - Engineer , Embedded Software \\n Number offer make - 1 \\n Selection Process \\n branch open - CS , EEE , ENI \\n CG Cutoff - 6 + \\n recruitment process - \\n Round 1 - Online Assessment \\n\\n round consist 5 question base Data Structures \\n Algorithms . easy . \\n Round 2 - technical interview \\n\\n round aim test fundamental Data Structures \\n Algorithms . \\n Round 3 - Technical Interview II'),\n",
              "  Document(page_content='role title suggest , client - face role . therefore , major \\n emphasis lie understand basic role fit test write \\n oral communication skill , well problem - solve aptitude . \\n\\n Round 2 - Personal interview \\n\\n round begin conversation around prior work experience , \\n hobby , interest . , proceed test problem - solve \\n aptitude ask reasoning question situational aptitude- \\n base question . \\n\\n Round 2 - Communication Round \\n\\n round intend test ability express thought , well \\n familiarity area interest company , ie . , cloud \\n computing . \\n Searce Inc. \\n 18 \\n Personal Experience \\n source preparation - \\n\\n specifically prepare role , background \\n communication well cloud computing greatly help \\n process . \\n word advice - \\n\\n client - face role , sure convey comfort \\n ability communicate individual across various background , \\n tech non - tech . \\n EEE f411 - Internet Things ( Discipline / Open Elective ) \\n course teach basic concept cloud computing require \\n course process . \\n\\n GS F221 - Business Communication \\n GS F223 - Introduction Mass Communication \\n gs f245 - effective Public Speaking \\n bits f226 - soft Skills professional \\n course could useful hone communication skill . \\n necessary interview process , one . fact , \\n course separate interview - relevant module . \\n Relevant Courses Certifications \\n Round 4 - Group Discussion Round')]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "xzWYqqWZ5t7v",
        "outputId": "a41b87fe-7178-44f3-f3fa-5d627381a715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The provided text doesn't contain information about relevant courses for Cohesity. It only mentions the relevant courses for the interviewee Hemant Seshadri Nemani and Sukriti Phogat. \n\nThanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **A Tricky Question for companies which hire in multiple domains**\n",
        "Ola cabs comes for hiring in chemical and tech placements both. So We can ask the model questions respectively by mentioning which field we are taking into consideration"
      ],
      "metadata": {
        "id": "XdL9v0LNjc8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the relevant courses for ola cabs in chemical placements?\"\n",
        "qa_chain = get_qa_chain(question)\n",
        "result = qa_chain({\"query\": question})\n",
        "result"
      ],
      "metadata": {
        "id": "mp84c8TB6CUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708631c1-5837-4488-cb5a-9d0f6443c632",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What are the relevant courses for ola cabs in chemical placements?',\n",
              " 'result': 'The relevant courses for Ola Cabs in chemical placements are:\\n\\n* **CHE f213 - Chemical Engineering Thermodynamics**\\n* **CHE F212 - Fluid Mechanics**\\n* **CHE F241 - Heat Transfer**\\n\\nThese courses cover the core chemical engineering concepts that are essential for a job in the chemical industry. \\n\\nThanks for asking! \\n',\n",
              " 'source_documents': [Document(page_content='comprise 30 question answer 30 minute . question \\n lengthy gate - level , cover knowledge thermodynamic , \\n fluid mechanic , heat , etc . one well prepared online \\n assessment computer - adaptive test , mean \\n difficulty level question would adjust per one ’s performance . \\n moreover , question design company , \\n point search internet . \\n Round 2 - Technical Interview \\n\\n test , 5 student shortlist whole Chemical \\n department two round interview conduct . \\n discussion base resume . question cover ML project , \\n Chemical project , core Chemical concept . \\n Ola Cabs \\n 26 \\n Personal Experience \\n source preparation -0 \\n $ ML project give significant advantage \\n candidate recruitment process \\n $ GATE preparation would suffice online test . \\n word advice -0 \\n $ build - rounder profile focus Academics , Personality , \\n Extra - curricular \\n $ try maximize cgpa much possible \\n $ Projects Internships rewarding project good reflection \\n resume . however , try keep internship \\n resume relevant role apply . \\n \\x88 CHE f213 - Chemical Engineering Thermodynamic } \\n \\x7f CHE F212 - Fluid Mechanic } \\n \\x82 CHE F241 - Heat Transfer \\n Relevant Courses Certifications \\n Round 3 - hr Round'),\n",
              "  Document(page_content='comprise 30 question answer 30 minute . question \\n lengthy gate - level , cover knowledge thermodynamic , \\n fluid mechanic , heat , etc . one well prepared online \\n assessment computer - adaptive test , mean \\n difficulty level question would adjust per one ’s performance . \\n moreover , question design company , \\n point search internet . \\n Round 2 - Technical Interview \\n\\n test , 5 student shortlist whole Chemical \\n department two round interview conduct . \\n discussion base resume . question cover ML project , \\n Chemical project , core Chemical concept . \\n Ola Cabs \\n 26 \\n Personal Experience \\n source preparation -0 \\n $ ML project give significant advantage \\n candidate recruitment process \\n $ GATE preparation would suffice online test . \\n word advice -0 \\n $ build - rounder profile focus Academics , Personality , \\n Extra - curricular \\n $ try maximize cgpa much possible \\n $ Projects Internships rewarding project good reflection \\n resume . however , try keep internship \\n resume relevant role apply . \\n \\x88 CHE f213 - Chemical Engineering Thermodynamic } \\n \\x7f CHE F212 - Fluid Mechanic } \\n \\x82 CHE F241 - Heat Transfer \\n Relevant Courses Certifications \\n Round 3 - hr Round'),\n",
              "  Document(page_content='precede Resume Shortlist , round comprise logical aptitude \\n behavioral question , judge candidate ’s mental reasoning skill . \\n\\n Round 2 - Technical Interview \\n\\n since job profile require deal patent different \\n company meet requirement , mixture technology \\n consulting . therefore , round , ask core electronic \\n concept previous project . \\n\\n Round 3 - Technical Interview \\n\\n round consist case study base patent . test \\n knowledge industry well reasoning skill . \\n unitedlex \\n 23 \\n Round 4 - hr Interview \\n\\n Basic HR question ask , test compatibility , teamwork , etc . \\n question also ask SDLC - Software Development Life Cycle . \\n Personal Experience \\n Prior internship experience - \\n\\n ps-1 Purchasing & Parts , remotely work Software \\n Developer . also Summer Intern Societe Generale , also \\n Software Developer . \\n word advice - \\n\\n Focus academic . let cg fall abysmally . \\n moreover , read company go interview , \\n always clear - headed keep calm . \\n Core - Chemical  \\n 24 \\n Present Past Recruiters \\n Ola Cabs \\n 25 \\n Ola Cabs \\n 25 \\n introduction \\n Interviewee - Arjun Singh Tyagi   ( 2019b5a10841p ) \\n Job Role - Chemical core \\n number offer make - 1 \\n Selection Process \\n branch open - Chemical \\n CG Cutoff - 6.5 \\n Recruitment process - \\n Round 1 - Online test'),\n",
              "  Document(page_content='precede Resume Shortlist , round comprise logical aptitude \\n behavioral question , judge candidate ’s mental reasoning skill . \\n\\n Round 2 - Technical Interview \\n\\n since job profile require deal patent different \\n company meet requirement , mixture technology \\n consulting . therefore , round , ask core electronic \\n concept previous project . \\n\\n Round 3 - Technical Interview \\n\\n round consist case study base patent . test \\n knowledge industry well reasoning skill . \\n unitedlex \\n 23 \\n Round 4 - hr Interview \\n\\n Basic HR question ask , test compatibility , teamwork , etc . \\n question also ask SDLC - Software Development Life Cycle . \\n Personal Experience \\n Prior internship experience - \\n\\n ps-1 Purchasing & Parts , remotely work Software \\n Developer . also Summer Intern Societe Generale , also \\n Software Developer . \\n word advice - \\n\\n Focus academic . let cg fall abysmally . \\n moreover , read company go interview , \\n always clear - headed keep calm . \\n Core - Chemical  \\n 24 \\n Present Past Recruiters \\n Ola Cabs \\n 25 \\n Ola Cabs \\n 25 \\n introduction \\n Interviewee - Arjun Singh Tyagi   ( 2019b5a10841p ) \\n Job Role - Chemical core \\n number offer make - 1 \\n Selection Process \\n branch open - Chemical \\n CG Cutoff - 6.5 \\n Recruitment process - \\n Round 1 - Online test'),\n",
              "  Document(page_content='ps-1 Purchasing & Parts , remotely work Software \\n Developer . also Summer Intern Societe Generale , also \\n Software Developer . \\n word advice - \\n\\n Focus academic . let cg fall abysmally . \\n moreover , read company go interview , \\n always clear - headed keep calm . \\n Core - Chemical  \\n 24 \\n Present Past Recruiters \\n Ola Cabs \\n 25 \\n Ola Cabs \\n 25 \\n introduction \\n Interviewee - Arjun Singh Tyagi   ( 2019b5a10841p ) \\n Job Role - Chemical core \\n number offer make - 1 \\n Selection Process \\n branch open - Chemical \\n CG Cutoff - 6.5 \\n Recruitment process - \\n Round 1 - Online test \\n\\n comprise 30 question answer 30 minute . question \\n lengthy gate - level , cover knowledge thermodynamic , \\n fluid mechanic , heat , etc . one well prepared online \\n assessment computer - adaptive test , mean \\n difficulty level question would adjust per one ’s performance . \\n moreover , question design company , \\n point search internet . \\n Round 2 - Technical Interview')]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "8CJYQ3vWgMEg",
        "outputId": "eb03f557-19af-4721-a05e-96450c1efcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The relevant courses for Ola Cabs in chemical placements are:\n\n* **CHE f213 - Chemical Engineering Thermodynamics**\n* **CHE F212 - Fluid Mechanics**\n* **CHE F241 - Heat Transfer**\n\nThese courses cover the core chemical engineering concepts that are essential for a job in the chemical industry. \n\nThanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the relevant courses for ola cabs in tech placements?\"\n",
        "qa_chain = get_qa_chain(question)\n",
        "result = qa_chain({\"query\": question})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1IrJ6g5gL-u",
        "outputId": "27082a5e-1882-44f1-949b-299948bbb589",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What are the relevant courses for ola cabs in tech placements?',\n",
              " 'result': 'The relevant courses for Ola Cabs tech placements are:\\n\\n* **CS F213 - Object-Oriented Programming:** This course is particularly helpful as it covers the fundamentals of object-oriented programming, which is essential for software development.\\n* **CS F211 - Data Structures and Algorithms:** This course is crucial for understanding the underlying principles of data structures and algorithms, which are essential for efficient software development.\\n* **CS F212 - Database Systems:** This course provides knowledge of database systems, which are essential for managing and storing large amounts of data, a critical aspect of many tech roles.\\n* **CS F303 - Computer Networks:** This course covers the fundamentals of computer networks, which are essential for understanding how data is transmitted and received over the internet.\\n* **CS F342 - Computer Architecture:** This course provides knowledge of computer architecture, which is essential for understanding how computers work at a low level.\\n* **CS F372 - Operating Systems:** This course covers the fundamentals of operating systems, which are essential for understanding how software interacts with hardware.\\n* **CS F464 - Machine Learning:** This course is particularly relevant for roles involving machine learning and data science.\\n\\nThanks for asking! \\n',\n",
              " 'source_documents': [Document(page_content='round entirely technical , focus resume basic \\n mathematical concept like Linearity property , Parametric , Polar , Implicit \\n Explicit equation . \\n\\n one Segmentation question ask - \" would identify object \\n different color image use graph ? \" \\n Round 2 - Technical \\n\\n give multiple scenario datum pull discussion datum \\n basis , networking , merge feature engineering . QuestionsÆ \\n Ð would build highly scalable model reach \\n entire world± \\n Ð since datum dynamic always upcoming , would implement \\n version control data± \\n Ð Discussion peer - - peer networking \\n Ola Cabs \\n 65 \\n Personal Experience \\n source preparation -/ \\n \\' LeetCode Striver Sheet DS \\x1c\\n \\' OOP course slide test decent enoug \\x1e\\n \\' textbook databases/ \\n \\' SQL lab sheet \\n word advice -/ \\n \\' personalize resume role companyE \\n \\' research company deeplyE \\n \\' not discourage one setback , keep strive \\n get ample amount opportunity bits Pilani . \\n CS F213 - object - orient Programming , particularly , study \\n material disburse course , quite helpful . \\n Relevant Courses Certifications \\n Round 3 - hr round'),\n",
              "  Document(page_content='round entirely technical , focus resume basic \\n mathematical concept like Linearity property , Parametric , Polar , Implicit \\n Explicit equation . \\n\\n one Segmentation question ask - \" would identify object \\n different color image use graph ? \" \\n Round 2 - Technical \\n\\n give multiple scenario datum pull discussion datum \\n basis , networking , merge feature engineering . QuestionsÆ \\n Ð would build highly scalable model reach \\n entire world± \\n Ð since datum dynamic always upcoming , would implement \\n version control data± \\n Ð Discussion peer - - peer networking \\n Ola Cabs \\n 65 \\n Personal Experience \\n source preparation -/ \\n \\' LeetCode Striver Sheet DS \\x1c\\n \\' OOP course slide test decent enoug \\x1e\\n \\' textbook databases/ \\n \\' SQL lab sheet \\n word advice -/ \\n \\' personalize resume role companyE \\n \\' research company deeplyE \\n \\' not discourage one setback , keep strive \\n get ample amount opportunity bits Pilani . \\n CS F213 - object - orient Programming , particularly , study \\n material disburse course , quite helpful . \\n Relevant Courses Certifications \\n Round 3 - hr round'),\n",
              "  Document(page_content='comprise 30 question answer 30 minute . question \\n lengthy gate - level , cover knowledge thermodynamic , \\n fluid mechanic , heat , etc . one well prepared online \\n assessment computer - adaptive test , mean \\n difficulty level question would adjust per one ’s performance . \\n moreover , question design company , \\n point search internet . \\n Round 2 - Technical Interview \\n\\n test , 5 student shortlist whole Chemical \\n department two round interview conduct . \\n discussion base resume . question cover ML project , \\n Chemical project , core Chemical concept . \\n Ola Cabs \\n 26 \\n Personal Experience \\n source preparation -0 \\n $ ML project give significant advantage \\n candidate recruitment process \\n $ GATE preparation would suffice online test . \\n word advice -0 \\n $ build - rounder profile focus Academics , Personality , \\n Extra - curricular \\n $ try maximize cgpa much possible \\n $ Projects Internships rewarding project good reflection \\n resume . however , try keep internship \\n resume relevant role apply . \\n \\x88 CHE f213 - Chemical Engineering Thermodynamic } \\n \\x7f CHE F212 - Fluid Mechanic } \\n \\x82 CHE F241 - Heat Transfer \\n Relevant Courses Certifications \\n Round 3 - hr Round'),\n",
              "  Document(page_content='comprise 30 question answer 30 minute . question \\n lengthy gate - level , cover knowledge thermodynamic , \\n fluid mechanic , heat , etc . one well prepared online \\n assessment computer - adaptive test , mean \\n difficulty level question would adjust per one ’s performance . \\n moreover , question design company , \\n point search internet . \\n Round 2 - Technical Interview \\n\\n test , 5 student shortlist whole Chemical \\n department two round interview conduct . \\n discussion base resume . question cover ML project , \\n Chemical project , core Chemical concept . \\n Ola Cabs \\n 26 \\n Personal Experience \\n source preparation -0 \\n $ ML project give significant advantage \\n candidate recruitment process \\n $ GATE preparation would suffice online test . \\n word advice -0 \\n $ build - rounder profile focus Academics , Personality , \\n Extra - curricular \\n $ try maximize cgpa much possible \\n $ Projects Internships rewarding project good reflection \\n resume . however , try keep internship \\n resume relevant role apply . \\n \\x88 CHE f213 - Chemical Engineering Thermodynamic } \\n \\x7f CHE F212 - Fluid Mechanic } \\n \\x82 CHE F241 - Heat Transfer \\n Relevant Courses Certifications \\n Round 3 - hr Round'),\n",
              "  Document(page_content='oa 2 hour long test comprising English , logic , code \\n question . four stage , stage hard last .   code \\n question revolve around Machine Learning ,   Data Science , Database \\n Systems . \\n Round 2 - Technical + HR Interview \\n\\n code round , 6 people shortlist one \\n round interview - start resume discussion , ask \\n question Operating Systems , Database Systems , well Data \\n Structures Algorithms . \\n National Payments Corporation India \\n ( NPCI ) \\n 63 \\n Personal Experience \\n source preparation - \\n\\n use LeetCode , GeeksforGeeks InterviewBit prepare \\n everything . slide CS cdc also pretty helpful cover \\n basic . \\n word advice - \\n\\n study basic everything CS thoroughly practice much DSA \\n possible . ’ \" good time \" start . importantly ,   not panic \\n confident answer . \\n \\x94\\x8f CS F211 - Data Structures Algorithm\\x89 \\n\\xa0 \\x8f CS F212 - Database System\\x89 \\n \\x81\\x8f CS F213 - Object - orient programmin\\x9e \\n { \\x8f CS F303 - Computer Network\\x89 \\n ~\\x8f CS F342 - Computer Architecturv \\n } \\x8f CS F372 - operate system\\x89 \\n s\\x8f bit F464 - Machine Learning \\n Relevant Courses Certifications \\n Ola Cabs \\n 64 \\n introduction \\n Interviewee - Sujay Rastogi   ( 2019b4a70741p ) \\n Job Role - Statistics \\n Number offer make - 2 ( 1 ML ) \\n Selection Process \\n branch open - \\n CG Cutoff -6 \\n Recruitment process - \\n Round 1 - tecnical \\n\\n round entirely technical , focus resume basic \\n mathematical concept like Linearity property , Parametric , Polar , Implicit \\n Explicit equation .')]}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(result[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "ejLXzWD3gYxH",
        "outputId": "0aab5213-0030-45d9-b6c7-f61a6fc63a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The relevant courses for Ola Cabs tech placements are:\n\n* **CS F213 - Object-Oriented Programming:** This course is particularly helpful as it covers the fundamentals of object-oriented programming, which is essential for software development.\n* **CS F211 - Data Structures and Algorithms:** This course is crucial for understanding the underlying principles of data structures and algorithms, which are essential for efficient software development.\n* **CS F212 - Database Systems:** This course provides knowledge of database systems, which are essential for managing and storing large amounts of data, a critical aspect of many tech roles.\n* **CS F303 - Computer Networks:** This course covers the fundamentals of computer networks, which are essential for understanding how data is transmitted and received over the internet.\n* **CS F342 - Computer Architecture:** This course provides knowledge of computer architecture, which is essential for understanding how computers work at a low level.\n* **CS F372 - Operating Systems:** This course covers the fundamentals of operating systems, which are essential for understanding how software interacts with hardware.\n* **CS F464 - Machine Learning:** This course is particularly relevant for roles involving machine learning and data science.\n\nThanks for asking! \n"
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K4m_Nj8sjo1E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}